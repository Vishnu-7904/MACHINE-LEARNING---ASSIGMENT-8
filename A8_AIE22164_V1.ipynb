{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tov02GZD5v9L"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "from math import log2\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#calculate the entropy of the target variable\n",
        "def entropy(y):\n",
        "    n = len(y)\n",
        "    counts = np.bincount(y)\n",
        "    probs = counts[np.nonzero(counts)] / n\n",
        "    entropy = -np.sum(probs * np.log2(probs))\n",
        "    return entropy\n",
        "\n",
        "#calculate the gain of the feature\n",
        "def information_gain(X, y, feature_idx):\n",
        "    total_entropy = entropy(y)\n",
        "\n",
        "    values, counts = np.unique(X[:, feature_idx], return_counts=True)\n",
        "    weighted_entropy = np.sum([(counts[i] / len(y)) * entropy(y[X[:, feature_idx] == values[i]]) for i in range(len(values))])\n",
        "\n",
        "    gain = total_entropy - weighted_entropy\n",
        "    return gain\n",
        "\n",
        "#finds the root node with the highest information gain\n",
        "def find_root_node(X, y):\n",
        "    num_features = X.shape[1]\n",
        "    gains = [information_gain(X, y, i) for i in range(num_features)]\n",
        "    print(gains)\n",
        "    root_feature_idx = np.argmax(gains)\n",
        "    return root_feature_idx\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"C:/Users/91914/Downloads/weatherAUS.csv\")\n",
        "df=pd.DataFrame(df)\n",
        "\n",
        "#merging 2 features in one array as base set\n",
        "def removeNull(Class):\n",
        "    iterate=df[Class]\n",
        "    y=[]\n",
        "    mean=df[Class].mean(axis=0)\n",
        "    for i in iterate:\n",
        "        if(math.isnan(i)):\n",
        "            y.append(mean)\n",
        "        else:\n",
        "            y.append(i)\n",
        "    y=pd.DataFrame(y)\n",
        "    df[Class]=y\n",
        "removeNull('WindGustSpeed')\n",
        "removeNull('WindSpeed9am')\n",
        "def labelencode(Class):\n",
        "    removeNullCategorical(Class)\n",
        "    temp=df[Class]\n",
        "    temp=temp.to_numpy()\n",
        "    temp=temp.flatten()\n",
        "    LE=LabelEncoder()\n",
        "    LE.fit(temp)\n",
        "    array=LE.transform(temp)\n",
        "    array=pd.DataFrame(array)\n",
        "    df[Class]=array\n",
        "\n",
        "def isNaN(string):\n",
        "    return string != string\n",
        "def removeNullCategorical(Class):\n",
        "    iterate=df[Class]\n",
        "    y=[]\n",
        "    mostfreq=df[Class].value_counts().idxmax()\n",
        "    for i in iterate:\n",
        "        if(isNaN(i)):\n",
        "            y.append(mostfreq)\n",
        "        else:\n",
        "            y.append(i)\n",
        "    y=pd.DataFrame(y)\n",
        "    df[Class]=y\n",
        "    return y\n",
        "\n",
        "removeNullCategorical('RainToday')\n",
        "labelencode('RainToday')\n",
        "y=df['RainToday'].to_numpy()\n",
        "X=df[['WindGustSpeed','WindSpeed9am']].to_numpy()\n",
        "\n",
        "root_feature_idx = find_root_node(X,y)\n",
        "print(\"Root node feature index:\", root_feature_idx)"
      ]
    }
  ]
}